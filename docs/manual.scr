@begin[ref=index](section)
   @title(Overview)
   @c(neural-classifier) is a library for working with neural networks and
   solving classification problem (and maybe other problems). For a basic use
   read README file on the
   @link[uri="http://github.com/shamazmazum/neural-classifier"](GitHub page).
   Here the API is described in more details.
@end(section)

@begin(section)
   @title(General information)
   Typical neural network lifecycle is the following:
   @begin(enum)
      @item(Adjust @c(neural-classifier:*learn-rate*),
            @c(neural-classifier:*decay-rate*) and
            @c(neural-classifier:*minibatch-size*) parameters if you want.)
      @item(Create a @c(snakes) generator which will return data for the
            training step in the form @c((CONS SAMPLE LABEL)) (i.e. cons pair
            which contains a sample for training and a label which describes
            that sample).)
      @item(Create four functions: The first and the second translate a sample
            returned by the generator created in the previous step to
            @c(magicl:matrix/single-float) matrix with dimensions @c(Nx1). One
            of them will be used by @c(calculate) and another one will be used
            during the training. The function used for training may make
            additional random transformations of the input data to extend
            training set. The third translates a label to
            @c(magicl:matrix/single-float) matrix with dimensions @c(Mx1) and
            the fourth translates a matrix with dimensions @c(Mx1)to a label.
            Obviously the third function is used for training and the
            fourth is used for classifing objects with trained net.)
      @item(Create a neural network with
            @c(neural-classifier:make-neural-network). The first parameter,
            @c(layout), must be a list @c((N ... M)), where @c(N) and @c(M) are
            taken from the previous step. Also is accepts created transformation
            functions.)
      @item(Train a neural network calling
            @c(neural-classifier:train-epoch). An epoch is finished when
            supplied generator doesn't have any more data (i.e. returns
            @c(snakes:generator-stop)).)
      @item(Repeat steps 2 and 5 to train for more epochs. You can use
            @c(neural-classifier:rate) function to control the accuracy of your
            network, so you know where to stop training.)
      @item(After the net is trained, call @c(neural-classifier:calculate) to
            pass your data through the net.)
   @end(enum)

If you want an example, look at @c(mnist/mnist.lisp) to see how digit
recognition works.
@end(section)

@begin(section)
   @title(API documentation)
   @u(Hyper-parameters)
   @cl:with-package[name="neural-classifier"](
      @cl:doc(variable *learn-rate*)
      @cl:doc(variable *decay-rate*)
      @cl:doc(variable *minibatch-size*)
   )
   @u(Neural network class and accessors)
   @cl:with-package[name="neural-classifier"](
      @cl:doc(class neural-network)
   )
   @u(Functions)
   @cl:with-package[name="neural-classifier"](
      @cl:doc(function make-neural-network)
      @cl:doc(function calculate)
      @cl:doc(function train-epoch)
      @cl:doc(function rate)
      @cl:doc(function idx-abs-max)
   )
@end(section)
